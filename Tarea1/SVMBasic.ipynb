{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Code Assigment 1\n",
        "\n",
        "For this assignment you will use the following SVM implementation for classifying these datasets:\n",
        "https://archive.ics.uci.edu/ml/datasets/banknote+authentication\n",
        "\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+\n",
        "\n",
        "You should:\n",
        "\n",
        "1) Specify which Machine Learning problem are you solving.\n",
        "\n",
        "2) Provide a short summary of the features and the labels you are working on.\n",
        "\n",
        "3) Please answer the following questions: a) Are these datasets linearly separable? b) Are these datasets randomly chosen and c) The sample size is enough to guarantee generalization.\n",
        "\n",
        "4) Provide an explanation how and why the code is working. You can add comments and/or formal explanations into the notebook.\n",
        "\n",
        "5) Show some examples to illustrate that the method is working properly.\n",
        "\n",
        "6) Provide quantitative evidence for generalization using the provided dataset.\n"
      ],
      "metadata": {
        "id": "s-y8Kil2snGk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "5AOO-Ib6o_7U",
        "outputId": "a46b2e50-4a88-489d-dc66-f1079d1bce6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized a step.\n",
            "Optimized a step.\n",
            "Optimized a step.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# https://pythonprogramming.net/svm-optimization-python-2-machine-learning-tutorial/?completed=/svm-optimization-python-machine-learning-tutorial/\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "style.use('ggplot')\n",
        "\n",
        "class Support_Vector_Machine:\n",
        "    def __init__(self, visualization=True):\n",
        "        self.visualization = visualization\n",
        "        self.colors = {1:'r',-1:'b'}\n",
        "        if self.visualization:\n",
        "            self.fig = plt.figure()\n",
        "            self.ax = self.fig.add_subplot(1,1,1)\n",
        "    # train\n",
        "    def fit(self, data):\n",
        "        self.data = data\n",
        "        # { ||w||: [w,b] }\n",
        "        opt_dict = {}\n",
        "\n",
        "        transforms = [[1,1],\n",
        "                      [-1,1],\n",
        "                      [-1,-1],\n",
        "                      [1,-1]]\n",
        "\n",
        "        all_data = []\n",
        "        for yi in self.data:\n",
        "            for featureset in self.data[yi]:\n",
        "                for feature in featureset:\n",
        "                    all_data.append(feature)\n",
        "\n",
        "        self.max_feature_value = max(all_data)\n",
        "        self.min_feature_value = min(all_data)\n",
        "        all_data = None\n",
        "\n",
        "        # support vectors yi(xi.w+b) = 1\n",
        "        \n",
        "\n",
        "        step_sizes = [self.max_feature_value * 0.1,\n",
        "                      self.max_feature_value * 0.01,\n",
        "                      # point of expense:\n",
        "                      self.max_feature_value * 0.001,]\n",
        "\n",
        "        \n",
        "        \n",
        "        # extremely expensive\n",
        "        b_range_multiple = 5\n",
        "        # we dont need to take as small of steps\n",
        "        # with b as we do w\n",
        "        b_multiple = 5\n",
        "        latest_optimum = self.max_feature_value*10\n",
        "\n",
        "        for step in step_sizes:\n",
        "            w = np.array([latest_optimum,latest_optimum])\n",
        "            # we can do this because convex\n",
        "            optimized = False\n",
        "            while not optimized:\n",
        "                for b in np.arange(-1*(self.max_feature_value*b_range_multiple),\n",
        "                                   self.max_feature_value*b_range_multiple,\n",
        "                                   step*b_multiple):\n",
        "                    for transformation in transforms:\n",
        "                        w_t = w*transformation\n",
        "                        found_option = True\n",
        "                        # weakest link in the SVM fundamentally\n",
        "                        # SMO attempts to fix this a bit\n",
        "                        # yi(xi.w+b) >= 1\n",
        "                        # \n",
        "                        # #### add a break here later..\n",
        "                        for i in self.data:\n",
        "                            for xi in self.data[i]:\n",
        "                                yi=i\n",
        "                                # Verifiy constraints\n",
        "                                if not yi*(np.dot(w_t,xi)+b) >= 1:\n",
        "                                    found_option = False\n",
        "                                    \n",
        "                        if found_option:\n",
        "                            # Computes norm\n",
        "                            opt_dict[np.linalg.norm(w_t)] = [w_t,b]\n",
        "\n",
        "                if w[0] < 0:\n",
        "                    optimized = True\n",
        "                    print('Optimized a step.')\n",
        "                else:\n",
        "                    w = w - step\n",
        "\n",
        "            norms = sorted([n for n in opt_dict])\n",
        "            #||w|| : [w,b]\n",
        "            opt_choice = opt_dict[norms[0]]\n",
        "            self.w = opt_choice[0]\n",
        "            self.b = opt_choice[1]\n",
        "            latest_optimum = opt_choice[0][0]+step*2\n",
        "            \n",
        "\n",
        "    def predict(self,features):\n",
        "        # sign( x.w+b )\n",
        "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
        "        return classification\n",
        "        \n",
        "        \n",
        "data_dict = {-1:np.array([[1,7],\n",
        "                          [2,8],\n",
        "                          [3,8],]),\n",
        "             \n",
        "             1:np.array([[5,1],\n",
        "                         [6,-1],\n",
        "                         [7,3],])}\n",
        "\n",
        "svm1 = Support_Vector_Machine()\n",
        "svm1.fit(data_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm1.predict([7,3.5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmE-qAQOqwJ8",
        "outputId": "bc369364-29c4-4155-a6c4-42d41027f887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}